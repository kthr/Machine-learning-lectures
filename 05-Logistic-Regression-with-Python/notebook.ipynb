{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "cb19f71d-51c8-417f-829e-3179d3319dcd",
    "_uuid": "c3b9226e142667d6b96e34daf7d6e42bea0ea1e2"
   },
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook is based on the Kaggle kernel by mnassrib (https://www.kaggle.com/mnassrib/titanic-logistic-regression-with-python/data).\n",
    "\n",
    "Like all regression analyses, the logistic regression is a predictive analysis. However, despite the name logistic *regression*, it is actually a method for doing (two-class) *classification* of a binary target variable.\n",
    "\n",
    "The aim is to predict the _probability_ of an observation to belong a class (C1 - yes/ C0 - no), given the input features $x$:  $p(C_1|x)=y(x)$. We will introduce some theoretical background of logistic regression in this notebook and then do classification by predicting survival using the Titanic dataset.\n",
    "\n",
    "But first let's look into some details of logistic regression..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "movie = pd.read_csv('./data/movie.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A toy dataset to see how logistic regression works\n",
    "\n",
    "We have a small dataset, that we will use to explain the idea of logistic regression. Let's assume we asked a few people that just came out of a cinema how old they are and if they liked the movie \"XYZ\". Then we will see if we can predict if someone will like the movie if we know the person's age. This is how our data look like:\n",
    "\n",
    "![](./img/movie-scatter.svg)\n",
    "\n",
    "So, the older people are the less they seem to enjoy the movie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression, a simplified explanation\n",
    "What could we do to predict if someone of a given age will like the movie? We could fit a linear regression. The result would look similar to this:\n",
    "\n",
    "![](./img/movie-linear.svg)\n",
    "\n",
    "There is a problem here. The linear regression predicts a continuous outcome y that can take any value between $-\\infty$ and $\\infty$. But what we want to predict is a binary outcome: We have two classes, people that liked the movie (y=1) and people that didn't like it (y=0). So linear regression is obviously not the best choice to model this problem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple solution: We use a threshold on the age variable and classify anything that is below this cutoff value for y as 1 and the rest as 0. It could look like that: \n",
    "\n",
    "![](./img/movie-threshold.svg)\n",
    "\n",
    "Although this looks like a good idea, this model is hard to optimize numerically (a threshold is not a differentiable function, it is not even continuous). Additionally, we can't really see how certain the model is in its decision. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a better idea: We will use a smooth (and differentiable) function that produces something like a smoothed threshold (and squashes the values of the regression between [0,1]). The we could interpret the result as a probability: the probability of liking the movie $y$, given the age $x$: $P(\"likes movie\"|x)$. A good nonlinear function to use is the logistic sigmoid:\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/8/88/Logistic-curve.svg)\n",
    "\n",
    "It has everything we need: it maps values from $(-\\infty, \\infty)$ to $(0,1)$, and it is smooth and differentiable. Nice..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we use this function and fit it to our data, the result looks like this:\n",
    "![](./img/movie-logistic.svg)\n",
    "\n",
    "We give the model the age and it will predict the probability of liking the movie. That is the basic idea of logistic regression. So we get a probability and then we can threshold it to get a classification, or use the probability as it is (e.g. in a Bayesian analysis). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A bit more mathematical explanation\n",
    "\n",
    "So why the logistic function? There is a deeper relation here. Let's start a bit more abstract. We need a function that takes the value x (the person is x years old) and outputs a probability $p(\"liked movie\"|x)$ (e.g. the person likes the movie). And we want to have a linear relationship between our explanatory variable $x$ and the prediction $p(\"liked movie\"|x)=y(w_1 x + w_0)$. We cannot predict a probability directly because a valid probability needs to lie in the range $[0,1]$, but we could predict the odds (https://en.wikipedia.org/wiki/Odds), the ratio of the probability to like the movie to the probability of not liking it: $\\frac{p(\"likes movie\")}{p(\"doesnt like movie\")}=\\frac{p(\"likes movie\")}{1-p(\"likes movie\")}$. This ratio lies in the interval $(0,\\infty)$, so we are getting closer, but we still cannot really predict it from a linear model, that outputs any real number (not just those $\\geq 0$). \n",
    "\n",
    "If we now just take the log of the odds (the _logit_): $\\log(\\frac{p(\"likes movie\")}{1-p(\"likes movie\")})$ we have some measure that lies in the range $(-\\infty,\\infty)$ and that we could nicely predict with a linear model: $\\log(\\frac{p(\"likes movie\"|w_1 x + w_0)}{1-p(\"likes movie\"|w_1 x + w_0)}) = w_1 x + w_0$. All we need is a function $\\sigma$ that satisfies the relation $\\log(\\frac{\\sigma(w_1 x + w_0)}{1-\\sigma(w_1 x + w_0)}) = w_1 x + w_0$. There is indeed a function with this property: the logistic sigmoid: $\\sigma(v)=\\frac{1}{1+\\exp(-v)}$. You can see that it works by substituting the definition of the sigmoid into $\\log(\\frac{\\sigma(w_1 x + w_0)}{1-\\sigma(w_1 x + w_0)}) = w_1 x + w_0$.\n",
    "\n",
    "So the sigmoid is exactly the nonlinear function that we need to use a linear regression model of the data and transform the outcome into a probability, so we can do prediction. In statistics, this nonlinear function is called the _link function_ and there is a particular link function for different problems. As we have seen, for binary classification, the link is the logistic sigmoid, for multi-class classification the link function will turn out to be the softmax. For those of you who worked with artificial neural networks before: This property of is exactly the reason why the sigmoid is used as the nonlinear activation function for binary classification problems. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A probabilistic view on classification\n",
    "\n",
    "We have a two-class classification problem, i.e. an observations falls into $C_1$ or $C_0$.\n",
    "We can use the class-conditional densities $p(x|C_k)$ and the class prior probabilities $p(C_k)$ to compute the posterior probabilities of the class given the observation using Bayes' theorem: \n",
    "$$p(C_1|x) = \\frac{p(x|C_1)p(C_1)}{p(x|C_1)p(C_1)+p(x|C_0)p(C_0)}.$$\n",
    "\n",
    "If we now define $o$ to be $$o(x) = \\log \\frac{p(x|C_1)p(C_1)}{p(x|C_0)p(C_0)} = \\log \\frac{p(x|C_1)p(C_1)}{1- p(x|C_1)p(C_1)}$$, and that means $o$ is simply the log odds, then we get: \n",
    "$$ p(C_1|x) = \\frac{1}{1+exp(-o)}$$ and this is indeed just the logistic sigmoid function $\\sigma(o)$. And indeed, its inverse is just the logit (log odds) function : $$o(\\sigma) = \\log \\frac{\\sigma}{1-\\sigma}.$$\n",
    "\n",
    "So if we model the log odds $o(x)$ as a linear function of the features $x$, we get a generalized linear model. So we compute a linear model of the inputs and use the sigmoid as a nonlinear function (called the activation function in neural networks) and end up with logistic regression. The name might be a bit confusing, as we actually used it for classification, but we are predicting a probability (a continuous outcome), so the name is not wrong... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assumptions for logistic regression\n",
    "\n",
    "- the outcome y to be predicted is a binary variable (yes/no)\n",
    "    - (y = 1 typically present the desired case.)\n",
    "- The features or covariates $x$ should be independent, i.e. there is no multicollinearity (or as little at possible).\n",
    "- the features $x$ are linearly related to log odds\n",
    "- we need a large sample sizes, i.e. you need at least 10 cases for the least likely outcome (see http://www.statisticssolutions.com/assumptions-of-logistic-regression/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doing Logistic Regression\n",
    "\n",
    "Let's try logistic regression on some real data...\n",
    "\n",
    "## The Titanic Data set\n",
    "\n",
    "The sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships.\n",
    "\n",
    "One of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class.\n",
    "\n",
    "In this challenge, we ask you to complete the analysis of what sorts of people were likely to survive. In particular, we ask you to apply the tools of machine learning to predict which passengers survived the tragedy.\n",
    "\n",
    "### Overview\n",
    "The data has been split into two groups:\n",
    "\n",
    "- training set (train.csv)\n",
    "- test set (test.csv)\n",
    "\n",
    "The training set should be used to build your machine learning models. For the training set, we provide the outcome (also known as the “ground truth”) for each passenger. Your model will be based on “features” like passengers’ gender and class. You can also use feature engineering to create new features.\n",
    "\n",
    "The test set should be used to see how well your model performs on unseen data. For the test set, we do not provide the ground truth for each passenger. It is your job to predict these outcomes. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic.\n",
    "\n",
    "### Data Dictionary\n",
    "\n",
    "Variable | Definition | Key\n",
    "---|---|---\n",
    "survival|Survival|0 = No, 1 = Yes\n",
    "pclass|Ticket class|1 = 1st, 2 = 2nd, 3 = 3rd\n",
    "sex|Sex|\n",
    "Age|Age in years|\n",
    "sibsp|# of siblings / spouses aboard the Titanic|\n",
    "parch|# of parents / children aboard the Titanic|\n",
    "ticket|Ticket number|\n",
    "fare|Passenger fare|\n",
    "cabin|Cabin number|\n",
    "embarked|Port of Embarkation\tC = Cherbourg, Q = Queenstown, S = Southampton|\n",
    "\n",
    "### Variable Notes\n",
    "\n",
    "**pclass**: A proxy for socio-economic status (SES)\n",
    "1st = Upper\n",
    "2nd = Middle\n",
    "3rd = Lower\n",
    "\n",
    "**age**: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\n",
    "\n",
    "**sibsp**: The dataset defines family relations in this way...\n",
    "Sibling = brother, sister, stepbrother, stepsister\n",
    "Spouse = husband, wife (mistresses and fiancés were ignored)\n",
    "\n",
    "**parch**: The dataset defines family relations in this way...\n",
    "Parent = mother, father\n",
    "Child = daughter, son, stepdaughter, stepson\n",
    "Some children travelled only with a nanny, therefore parch=0 for them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "33c91cae-2ff8-45a6-b8cb-671619e9c933",
    "_uuid": "0a395fd25f20834b070ef55cb8987c8c1f9b55f9"
   },
   "source": [
    "<a id=\"t1.\"></a>\n",
    "# 1. Import Data & Python Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "de05512e-6991-44df-9599-da92a7e459ac",
    "_uuid": "d8bdd5f0320e244e4702ed8ec1c2482b022c51cd",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt \n",
    "plt.rc(\"font\", size=14)\n",
    "import seaborn as sns\n",
    "sns.set(style=\"white\") #white background style for seaborn plots\n",
    "sns.set(style=\"whitegrid\", color_codes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will read the data from a csv file into a pandas DataFrame. We only use the training data from the Kaggle competition as the test set doesn't have the target values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e0a17223-f682-45fc-89a5-667af9782bbe",
    "_uuid": "7964157913fbcff581fc1929eed487708e81ac9c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"./data/train.csv\")\n",
    "\n",
    "# preview the data organization\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "872d0de9-a873-4b60-b1ee-d557ee39d8a1",
    "_uuid": "d38222a64d4dfd1d1ee1a7ee1f58c4aa54560de3",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('The number of samples in the train data is {}.'.format(train_df.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "6578c0da-7bcf-433d-9f28-a66d8dfa6fa3",
    "_uuid": "8660e63a62c2fcdb4f7633380166438caf5edae9"
   },
   "source": [
    "<a id=\"t2.\"></a>\n",
    "# 2. Data Quality & Missing Value Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will check the quality of the data, and the most important aspect are missing entries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "29dddd33-d995-4b0f-92ea-a361b368cc42",
    "_uuid": "d4fe22ead7e187724ca6f3ba7ba0e6412ae0e874",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have quite a few missing values. Around 20% of entries have no value for \"age\", 77% of the entries have no \"Cabin\", and in two cases, the \"embarked\" information is missing. There are basically three strategies how you can deal with this problem: \n",
    "- use imputation to fill in the missing values with a reasonable guess or\n",
    "- remove each observation (row) with missing values.\n",
    "- remove the feature (column) with missing values from the entire dataset.\n",
    "\n",
    "To keep it simple, we will remove the \"cabin\" feature completely, and also remove all observations, where \"age\" is missing (it is a useful feature if it is known, so we keep this feature). And we will just fill the two missing \"embarked\" entries with the most common value from the rest of the data (imputation).\n",
    "\n",
    "However, another (better?) strategy is to use imputation for the \"age\" feature as well, as we wouldn't throw away ~20% of our observations. You could use the mean or median value to replace the missing values or you could sample it from a uniform distribution or from the data itself. We will leave this as an exercise. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "0e696cff-ca80-4cb5-862c-ee80f4b1ab1f",
    "_uuid": "d575319b1f528c7a153d8ab680282048cb163b14"
   },
   "source": [
    "### Imputation for \"embarked\" missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "22924bc4-5dfa-4df7-b0d0-de3ede9c58b7",
    "_uuid": "f2a915f45264f8a580de6cc382d96b370eb75730",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Boarded passengers grouped by port of embarkation (C = Cherbourg, Q = Queenstown, S = Southampton):')\n",
    "print(train_df['Embarked'].value_counts())\n",
    "sns.countplot(x='Embarked', data=train_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c4c55f99-ce99-44f9-b7a8-d4d623ae9295",
    "_uuid": "19cfaae8c484dcb1d00f69b2771e86dc249e9793"
   },
   "source": [
    "Most passengers boarded in Southhampton, so we'll use this value (\"S\") to fill the missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "684c308f-25ae-4039-9332-ddb58953a054",
    "_uuid": "3609e785d210d5a8110f7ce550e61007d066449b"
   },
   "source": [
    "## cleaning up the data  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b3025cdc-fe9f-43b6-bda1-e45c1f25e77c",
    "_uuid": "06d2762ccec3f11564870fe941fc9ac45d71662f"
   },
   "source": [
    "We will now remove the rows (observations) with missing \"age\" value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "bc0d7121-1008-4890-9043-07eba1524e15",
    "_uuid": "feeed4b6775f88edf5de12b0ee6ee73c16eba61d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = train_df.copy()\n",
    "#train_data[\"Age\"].fillna(train_df[\"Age\"].median(skipna=True), inplace=True)\n",
    "train_data=train_data.dropna(subset=[\"Age\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will get rid off the 'cabin' column (feature) entirely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.drop('Cabin', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we will impute the missing 'embarked' information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"Embarked\"].fillna(train_df['Embarked'].value_counts().idxmax(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and check if it worked..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0cfe1c08-71a6-493e-803d-db255af01697",
    "_uuid": "d6be29651bb903964e02d3a7bcc7033513eb76c9",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# check missing values in adjusted train data\n",
    "train_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "6925fcc2-977b-4369-85e1-77a9210326a7",
    "_uuid": "d8280757e6bc627821fb0540c87ccd6ca110f1e0"
   },
   "source": [
    "### creating dummy variables for categorical features\n",
    "\n",
    "It is good practice to encode some categorical variables into dummy variables (using only 0 and 1). see here: https://en.wikipedia.org/wiki/Dummy_variable_(statistics)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e4a22367-b719-4204-952f-d2e9a3b8075e",
    "_uuid": "ca53796bf788bd3b015f1a79a97e050bafa2c770"
   },
   "source": [
    "We'll create dummy variables for the port where the journey began (\"Embarked\") and for the \"Sex\" variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f95361e8-2533-4731-a7ab-a99cf686ed50",
    "_uuid": "4494fcbf9faa90151e20042f74d73395fac3cc8e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create categorical variables and drop some variables\n",
    "training=pd.get_dummies(train_data, columns=[\"Embarked\",\"Sex\"])\n",
    "training.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To keep it simpler, we'll drop the features \"name\", \"passengerID\", and \"ticket\" as they are not obviously predictive for survival. Although you might still be able to infer something interesting from this information. We also drop the feature \"Sex_male\" as it is already encoded in \"Sex_female\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training.drop('Sex_male', axis=1, inplace=True)\n",
    "training.drop('PassengerId', axis=1, inplace=True)\n",
    "training.drop('Name', axis=1, inplace=True)\n",
    "training.drop('Ticket', axis=1, inplace=True)\n",
    "final_train = training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are interested in further ideas of how to transform the data, have a look at the examples here: http://www.ultravioletanalytics.com/blog/kaggle-titanic-competition-part-i-intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add additional (derived) features\n",
    "\n",
    "Here you could use some of the existing information and add some new features (or replace old ones with them). For example, you could remove the 'SibSp' (traveling with siblings or spouses) and 'Parch' (traveling with parents or children) and introduce a new binary feature like 'travelingAlone', see the commented code below. Just as an idea. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create categorical variable for traveling alone\n",
    "# train_data['TravelAlone']=np.where((train_data[\"SibSp\"]+train_data[\"Parch\"])>0, 0, 1)\n",
    "# train_data.drop('SibSp', axis=1, inplace=True)\n",
    "# train_data.drop('Parch', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1430d510-1c8d-4544-8009-3911fff7afbb",
    "_uuid": "4e26c19bf719b7086addc0e1981c00836a19f189"
   },
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how our final data set looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is a good idea to plot the distribution of some features and also look into correlations between features to decide, which you want to keep in the regression analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2655428b-d69d-4c0f-85ff-e31ada8e37b9",
    "_uuid": "32e9c04a3281fb1aa8c77e1406c56cd820459202"
   },
   "source": [
    "### plotting the distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "9f9ca9e5-50a0-4487-ba53-815dda90af1c",
    "_uuid": "790e8d7ca89d19e276b3398e299c42893a796b79",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_numerical(feature): \n",
    "    plt.figure(figsize=(15,8))\n",
    "    p1=sns.distplot(final_train[feature][final_train.Survived == 1], kde=False)\n",
    "    p2=sns.distplot(final_train[feature][final_train.Survived == 0], kde=False)\n",
    "    plt.legend(['Survived', 'Died'])\n",
    "    ax=p1.axes\n",
    "    ax.set(xlabel=feature)\n",
    "    plt.show()\n",
    "    \n",
    "def plot_categorical(feature):\n",
    "    plt.figure()\n",
    "    sns.barplot(feature, 'Survived', data=final_train)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_categorical(\"Pclass\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_numerical(\"Fare\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can explore the features and then think about which ones you would like to include into the model. We will later show a way to use automated methods for feature selection. But it is still good practice to explore your data first, before you blindly rely on computational results (see https://en.wikipedia.org/wiki/Anscombe%27s_quartet and even more impressive here: https://www.autodeskresearch.com/publications/samestats). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c833cbf5-74db-44ff-90fa-b600ff0a09d7",
    "_uuid": "39dbc095f99dcec6d25a7a4561e81bb641078622"
   },
   "source": [
    "<a id=\"t4.\"></a>\n",
    "# 4. Logistic Regression and Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute a simple model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to fit a logistic regression model to the data. In the code below we will use \"age\" and \"fare\" to predict survival. Keep in mind that Machine Learning is not (only) optimization, instead of searching for a perfect fit to the training data we want to be able to predict unseen observation. To analyze the performance of the logistic regression model, we thus split the data again into a training set and a test set. We optimize the parameters using the observations from the training set. We then use the observations from the test set to validate how well our method can generalize to 'new' data. There are several ways to approach this, you will find different measures below..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "# create X (features) and y (response)\n",
    "Selected_features = [\"Age\",\"Fare\",\"Sex_female\"] \n",
    "X = final_train[Selected_features]\n",
    "y = final_train['Survived']\n",
    "\n",
    "# use train/test split with different random_state values\n",
    "# we can change the random_state values that changes the accuracy scores\n",
    "# the scores change a lot, this is why testing scores is a high-variance estimate\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods to quantify the performance of the classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy\n",
    "\n",
    "The simplest approach: Train the classfier on the training data and predict the obervations from the test set. Then we will look at the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=0)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "logreg=LogisticRegression()\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predicting the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logreg.predict(X_test)\n",
    "print('Accuracy of logistic regression on test set: {:.2f}'.format(logreg.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation\n",
    "\n",
    "We can use [Cross Validation](https://en.wikipedia.org/wiki/Cross-validation_(statistics)) to get an average estimate of how our model perfoms. We will use 10 fold Cross Validation to test the model, i.e. we split the data into 10 subsets, and then use 9 sets for training and predict the 10th set. This procedure will be iterated for all 10 subsets and finally we compute the average accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import cross_val_score\n",
    "kfold = model_selection.KFold(n_splits=10,random_state=7)\n",
    "modelCV = LogisticRegression()\n",
    "scoring='accuracy'\n",
    "results = model_selection.cross_val_score(modelCV, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "print(\"10-fold cross validation average accuracy: %.3f\" % (results.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix\n",
    "\n",
    "A good way to visualize the performance is by looking at the confusion matrix (https://en.wikipedia.org/wiki/Confusion_matrix). It shows for each class (rows) of the observation, which class the model has predicted, i.e. ideally we only have nonzero entries at the diagonal (where actual class = predicted class). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision, Recall, F-score, and support\n",
    "\n",
    "The precision is the ratio tp / (tp + fp) where tp is the number of true positives and fp the number of false positives. The precision is intuitively the ability of the classifier to not label a sample as positive if it is negative.\n",
    "\n",
    "The recall is the ratio tp / (tp + fn) where tp is the number of true positives and fn the number of false negatives. The recall is intuitively the ability of the classifier to find all the positive samples.\n",
    "\n",
    "The F-beta score can be interpreted as a weighted harmonic mean of the precision and recall, where an F-beta score reaches its best value at 1 and worst score at 0.\n",
    "\n",
    "The F-beta score weights the recall more than the precision by a factor of beta. beta = 1.0 means recall and precision are equally important.\n",
    "\n",
    "The support is the number of occurrences of each class in y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC curve\n",
    "\n",
    "The receiver operating characteristic (ROC) curve is another common tool used with binary classifiers. The dotted line represents the ROC curve of a purely random classifier; a good classifier stays as far away from that line as possible (toward the top-left corner).\n",
    "You'll find more information here https://en.wikipedia.org/wiki/Receiver_operating_characteristic. Below you will find the code to plot the curve. The area under the ROC curve will give us a single measure of performance. The closer \"logit_roc_auc\" is to 1, the better our predictions are. (A simple explanation can be found here: https://datamize.wordpress.com/2015/01/24/how-to-plot-a-roc-curve-in-scikit-learn/) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "logit_roc_auc = roc_auc_score(y_test, logreg.predict(X_test))\n",
    "fpr, tpr, thresholds = roc_curve(y_test, logreg.predict_proba(X_test)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your turn\n",
    "\n",
    "OK. So we have around 60% accuracy with the two features \"age\" and \"fare\". But we can do better of course. Now you should go back to the point 4 above and change the \"Selected_features\" variable to include the features you would want to test as predictors. Below you will find the code to plot the correlation between the features. The correlation is something you may want to think about when you decide which features to include..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_train\n",
    "\n",
    "plt.subplots(figsize=(8, 5))\n",
    "sns.heatmap(X.corr(), annot=True, cmap='RdBu')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b70cda8a-e8d9-44a6-b9f0-2b365fdf3428",
    "_uuid": "136cf9e02ea1ab48a397f534b491fb2d9dbb5684"
   },
   "source": [
    "\n",
    "## Automated Feature selection\n",
    "\n",
    "Recursive feature elimination (RFE) is to select features by recursively considering smaller and smaller sets of features. First, the estimator is trained on the initial set of features and the importance of each feature is obtained either through a `coef_ attribute` or through a `feature_importances_` attribute. Then, the least important features are removed from current set of features. The procedure is recursively repeated on the reduced set until the desired number of features to select is reached (here we used 4 but you can change that...).\n",
    "\n",
    "http://scikit-learn.org/stable/modules/feature_selection.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features=list(final_train.columns)[1:]\n",
    "all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "11a2a468-20df-40cd-a4ba-4ae7bd2fc403",
    "_uuid": "64befdf1182c2b4e845f488f5bfd0e19ce3dc17a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "cols = all_features \n",
    "X = final_train[cols]\n",
    "y = final_train['Survived']\n",
    "# Build a logreg and compute the feature importances\n",
    "model = LogisticRegression()\n",
    "# create the RFE model and select 4 attributes\n",
    "rfe = RFE(model, 4)\n",
    "rfe = rfe.fit(X, y)\n",
    "# summarize the selection of the attributes\n",
    "print('Selected features: %s' % list(X.columns[rfe.support_]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "29281bd5-b954-4f3d-87e3-7416b1ec8c6b",
    "_uuid": "626da3348b48ced3564e6e05bdb0c3b4bd1402e6"
   },
   "source": [
    "### Feature ranking with recursive feature elimination and cross-validation\n",
    "\n",
    "There is another (and probably) better way than selecting the number of features to include beforehand. It is calles recursive feature elimination and cross validation. RFECV performs RFE in a cross-validation loop to find the optimal number or the best number of features. This automatically tunes the number of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7239aa6f-7fd2-4b75-a387-f6624f1c338c",
    "_uuid": "53d79f38cfe33d75d6ff869a443b9a29c93b4cbd",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "# Create the RFE object and compute a cross-validated score.\n",
    "# The \"accuracy\" scoring is proportional to the number of correct classifications\n",
    "rfecv = RFECV(estimator=LogisticRegression(), step=1, cv=10, scoring='accuracy')\n",
    "rfecv.fit(X, y)\n",
    "\n",
    "print(\"Optimal number of features: %d\" % rfecv.n_features_)\n",
    "print('Selected features: %s' % list(X.columns[rfecv.support_]))\n",
    "\n",
    "# Plot number of features VS. cross-validation scores\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1b3b56f-2f5f-47d6-9375-62c11e49ce79",
    "_uuid": "e9d52d5b182c0a01218982e844e53d5278e0d98a"
   },
   "source": [
    "As we see, eight variables (all but one) were kept. The \"Fare\" feature did not make it in the final list. Do you have an idea why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d1c62457-c24e-4cd3-aae8-783dc3761338",
    "_uuid": "fa6c3dce74afe9a849351dffbeaa411533264a48",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Selected_features=list(X.columns[rfecv.support_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_train[Selected_features]\n",
    "y = final_train['Survived']\n",
    "\n",
    "# use train/test split with different random_state values\n",
    "# we can change the random_state values that changes the accuracy scores\n",
    "# the scores change a lot, this is why testing scores is a high-variance estimate\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "model=logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "logit_roc_auc = roc_auc_score(y_test, logreg.predict(X_test))\n",
    "fpr, tpr, thresholds = roc_curve(y_test, logreg.predict_proba(X_test)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are not yet satisfied with the results, you can go back and change the way we've dealt with missing values in the 'age' column, or you could add other features. If you need inspiration, have a look at this site: http://www.ultravioletanalytics.com/blog/kaggle-titanic-competition-part-i-intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this is the end of this notebook, I hope you've learned something useful about Logistic Regression and thanks a lot for you time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
