Before we start... 
# organisational stuff

- 30 min theory, 30 min Python notebook hacking
- first 3 or 4 weeks theory only
- no course on Nov 15th

## Outline of course

1. Introduction: What is Machine Learning? 
2. Mathematical Background 
	1. Linear Algebra (from [2])
	1. Probability theory (from [1], [2], [3]) 
	2. Model selection
	3. Curse of dimensionality
	4. Decision theory
	5. Information theory
3. Machine Learning Basics (from [2])
4. Introduction to Python, Jupyter, scikit-learn, pandas...
5. Linear models for regression
6. Linear models for classification 
7. *GLMs and exponential family*
8. Kernel methods and sparse kernel machines
9. Mixture Models and EM
10. Adaptive basis function models - Classification and Regression Trees (CART)
11. *(Directed) Graphical Models*
12. (Continuous) Latent Variables -  Dimensionality Reduction
13. Clustering 
14. *Nonparametric methods [6]*
15. Neural networks
16. *Introduction to Tensorflow / Keras*
17. Deep learning

------------
# Literature

- [1] Pattern Recognition and Machine Learning - Bishop
- [2] Deep Learnig - Goodfellow, Bengio, Courville
- [3] Machine Learning: A Probabilistic Perspective - Murphy
- [4] The Elements of Statistical Learning - Hastie, Tibshirani, Friedman
- [5] (Artificial Intelligence: A modern approach - Russel, Norvig)
- [6] Introduction to Machine Learning - Alpaydin

---------------------

# Lecture 1: What is Machine Learning?

----

reading:

- Murphy Ch. 1
- Bishop Ch. 1
- Goodfellow [Ch. 1](http://www.deeplearningbook.org/contents/intro.html) and [Ch. 5](http://www.deeplearningbook.org/contents/ml.html)
- [Domingos, Pedro. 2012. “A Few Useful Things to Know About Machine Learning.” Communications of the ACM 55 (10). New York, NY, USA: ACM: 78–87.](https://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf)

